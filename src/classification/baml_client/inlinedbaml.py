###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> OpenRouterGPT4oMini {\n  provider \"openai-generic\"\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.OPENROUTER_API_KEY\n    model \"openai/gpt-4o-mini\"\n    headers {\n      \"HTTP-Referer\" \"https://thedataquarry.com\" // Optional\n      \"X-Title\" \"thedataquarry\" // Optional\n    }\n  }\n}\n\nclient<llm> OpenRouterGemma3_27b {\n  provider \"openai-generic\"\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.OPENROUTER_API_KEY\n    model \"google/gemma-3-27b-it:free\"\n    headers {\n      \"HTTP-Referer\" \"https://thedataquarry.com\" // Optional\n      \"X-Title\" \"thedataquarry\" // Optional\n    }\n  }\n}\n\n// Custom LLM inference server by YourTechBud\nclient<llm> Inferix_Gemma3_27b {\n  provider openai-generic\n  options {\n    base_url \"https://inferix.yourtechbud.studio/inferix/v1/llm\"\n    api_key env.INFERIX_API_KEY\n    model \"gemma3:27b\"\n    max_tokens 500\n  }\n}\n\nclient<llm> Inferix_Gemma3_12b {\n  provider openai-generic\n  options {\n    base_url \"https://inferix.yourtechbud.studio/inferix/v1/llm\"\n    api_key env.INFERIX_API_KEY\n    model \"gemma3:12b\"\n    max_tokens 500\n  }\n}\n\nclient<llm> Ollama_Gemma3_27b {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model \"gemma3:27b\"\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "genderize.baml": "enum Gender {\n  Male\n  Female\n  Unknown\n}\n\nfunction ClassifyGender(info: string) -> Gender {\n  client Inferix_Gemma3_27b\n  prompt #\"\n    Based on your knowledge of historical scholars and scientists, determine the likely gender of this person.\n    Scholars who are termed \"laureates\" won the Nobel Prize in a category.\n\n    ONLY respond with one gender.\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }}\n    {{ info }}\n  \"#\n}\n\n\ntest ClassifyAaronKlug {\n  functions [ClassifyGender]\n  args {\n    info \"name: Aaron Klug\\ninfo: 1982 Chemistry Nobel Prize\"\n  }\n}\n\n\ntest ClassifyAbbaLerner {\n  functions [ClassifyGender]\n  args {\n    info \"name: Abba Lerner\\ninfo: 1974 Physics Nobel Prize\"\n  }\n}\n\ntest ClassifyAJFMBrochantDeVilliers {\n  functions [ClassifyGender]\n  args {\n    info \"name: AJFM Brochant de Villiers\\ninfo: scholar\"\n  }\n}\n\ntest ClassifyElaineTuomanen {\n  functions [ClassifyGender]\n  args {\n    info \"name: Elaine Tuomanen\\ninfo: scholar\"\n  }\n}\n\ntest ClassifyAbdusSalam {\n  functions [ClassifyGender]\n  args {\n    info \"name: Abdus Salam\\ninfo: 1979 Physics Nobel Prize\"\n  }\n}\n\ntest ClassifyAndreaGhez {\n  functions [ClassifyGender]\n  args {\n    info \"name: Andrea Ghez\\ninfo: 2020 Physics Nobel Prize\"\n  }\n}\n\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.78.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return file_map